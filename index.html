<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tommy Hinks - Making numbers count</title>
</head>
<body style="font-family:sans-serif; max-width:800px; margin:3rem auto;">
  <h1>Hello</h1>
  <p>This is my GitHub Pages site.</p>

  <p>
    <a href="https://github.com/thinks">My GitHub</a>
  </p>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">


  <h2>PhD<br>Geometric Processing Techniques for Urban Aerial Laser Scan Data</h2>
  <img src="images/phd_banner2.png"
     style="max-width:100%; height:auto;">  
  <p>
    My PhD studies focused on the acquisition and processing of high resolution Aerial Laser Scanning (ALS) data sets. In particular, processing task such as building extraction and modeling for urban areas were studied.
  </p>
  <h3>Abstract</h3>
  <p>
    Current Aerial Laser Scanning (ALS) technology rapidly produces large amounts of accurate point data for urban regions, making it a suitable tool for city-scale geometric modeling of buildings. However, acquisition and processing of urban ALS data remains a challenge because of the geometric complexity of urban scenes. Existing techniques have focused on geometric modeling from elevation data, ignoring details on building walls. This thesis introduces several improvements and simplifications for the acquisition and processing of ALS data: urban flight path planning, scan line analysis, visualization, building extraction, and simple and robust conversion of ALS data into solid models for further processing. By applying geometric reasoning, it is shown that certain flight paths vastly improve the point data quality on building walls. Single scan line analysis then exploits latent information in the data to insert missing echoes caused by undetected pulse reflections, and to identify building wall segments in individual scan lines. Points on building wall segments are then transferred to a digital image and complete building footprints are then extracted using innovative morphological techniques. Finally, a simple and robust method for direct conversion of point data into solid models based on volumetric subdivision rather than surface reconstruction is presented.
  </p>
  <p>
    <a href="docs/thinks-thesis-single.pdf" target="_blank" rel="noopener">thesis [.pdf]</a> | <a href="docs/viva_thinks.pdf" target="_blank" rel="noopener">presentation [.pdf]</a>
  </p>  

  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/phd_occlusion_full1.png" target="_blank" rel="noopener">
          <img src="images/phd_occlusion_full_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_maxwell_hfield2.png" target="_blank" rel="noopener">
          <img src="images/phd_maxwell_hfield_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_building_extraction1.pdf" target="_blank" rel="noopener">
          <img src="images/phd_building_extraction_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_fem_test3.png" target="_blank" rel="noopener">
          <img src="images/phd_fem_test_thumb1.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
    </tr>
  </table>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>MSc<br>Animating Wind-Driven Snow Build-up Using an Implicit Approach</h2>
  <img src="images/snow_feldman3.png"
     style="max-width:100%; height:auto;">  
  <p>
    My master thesis focused on modeling snow buildup using implicit surfaces (more specifically level sets) by allowing snow to fall in a wind field. Level sets are propagated according to snow particle collisions, with constraints to mimic realistic buildup.
  </p>
  <p>
    <a href="docs/tommyfinalthesis.pdf" target="_blank" rel="noopener">thesis [.pdf]</a>
  </p>  
  <h3>Abstract</h3>
  <p>
    We present a physically-based snow modeling approach that handles geometrically complex scenes and arbitrary amounts of accumulated snow. Scene objects are represented with a novel dual level set structure. This implicit surface representation produces smooth snow surfaces that adhere to granular stability constraints at every timestep. Realistic accumulation patterns are achieved by tracing snow-carrying particles in a dynamic wind-field and on the surfaces of objects. Local level set operations are used to deposit snow at surface locations for which accumulation is physically plausible. The effectiveness of our method is demonstrated by applying our method to a number of challenging scenes.
  </p>
  <h3>Paper</h3>
  <p>
    “Wind-Driven Snow Buildup Using a Level Set Approach”,<br>
    <b>T. Hinks</b>, K. Museth,<br>
    <i>Eurographics Ireland Workshop Series</i>, Vol. 9, December 2009, Dublin, Ireland, pp. 19-26.  
  </p>
  <p>
    <a href="docs/eg09irl_snow.pdf" target="_blank" rel="noopener">paper [.pdf]</a> | <a href="docs/eg09irl_snow_pres.pdf" target="_blank" rel="noopener">presentation [.pdf]</a> - <span style="color: rgb(255, 136, 0);">Best presentation award!</span>
  </p>

  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420a.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420a.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420b.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420b.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420c.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420c.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>

    <tr>
      <td style="text-align:center;">
        <a href="images/snow_feldman.png" target="_blank" rel="noopener">
          <img src="images/snow_feldman.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_buddha.png" target="_blank" rel="noopener">
          <img src="images/snow_buddha.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_lantern.jpg" target="_blank" rel="noopener">
          <img src="images/snow_lantern.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>Peer-reviewed Publications</h2>
  <ul>
    <li>
      <p>
        ”Visualisation of urban airborne laser scanning data with occlusion images”,<br>
        <b>T. Hinks</b>, H. Carr, H. Gharibi, D. Laefer,<br>
        <i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, Vol. 104, June 2015, pp. 77-87. <a href="http://dx.doi.org/10.1016/j.isprsjprs.2015.01.014" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        ”Point Cloud Data Conversion into Solid Models via Point-Based Voxelization”,<br>
        <b>T. Hinks</b>, H. Carr, L. Truong-Hong, D. Laefer,<br>
        <i>J. Surv. Eng.</i>, Vol. 139, No. 2, May 2013, pp. 72-83. <a href="http://dx.doi.org/10.1061/(ASCE)SU.1943-5428.0000097" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “Combining an Angle Criterion with Voxelization and the Flying Voxel Method in Reconstructing Building Models from LiDAR Data”,<br>
        L. Truong-Hong, D.F. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>Computer-Aided Civil and Infrastructure Engineering</i>, Vol. 28, No. 2, February 2013, pp. 112-129. <a href="http://dx.doi.org/10.1111/j.1467-8667.2012.00761.x" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “Flying Voxel Method with Delaunay Triangulation Criterion For Façade/Feature Detection For Computation”,<br>
        L. Truong-Hong, D. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>J. of Computing in Civil Eng.</i>, ASCE. <a href="http://dx.doi.org/10.1061/(ASCE)CP.1943-5487.0000188" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “New Advances in Automated Urban Modelling from Airborne Laser Scanning Data”,<br>
        D.F. Laefer, <b>T. Hinks</b>, H. Carr, L. Truong-Hong,<br>
        <i>Recent Patents on Engineering</i>, Bentham Science Publishers, Vol. 5, No. 3, December 2011, pp. 196-208. <a href="http://dx.doi.org/10.2174/187221211797636890" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “New possibilities for damage prediction from tunnel subsidence using aerial LiDAR data”,<br>
        D.F. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>Geotechnical Challenges in Megacities</i>, Vol. 2, June 7-10, 2010, ISSMGE Moscow, pp. 622-629.
      </p>
      <p>
        <a href="docs/2010_new_possibilities_for_damage_prediction_from_tunnel_subsidence_using_aerial_lidar_data.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Wind-Driven Snow Buildup Using a Level Set Approach”,<br>
        <b>T. Hinks</b>, K. Museth,<br>
        <i>Eurographics Ireland Workshop Series</i>, Vol. 9, December 2009, Dublin, Ireland, pp. 19-26.  
      </p>
      <p>
        <a href="docs/eg09irl_snow.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Flight Optimization Algorithms for Aerial LiDAR Capture for Urban Infrastructure Model Generation”,<br>
        <b>T. Hinks</b>, H. Carr, D.F. Laefer,<br>
        <i>Journal of Computing in Civil Engineering</i>, Vol. 23, No. 4, November/December 2009, pp. 330-339.
      </p>
      <p>
        <a href="docs/jcce09.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Post Facto Registration Tools for Urban Modelling”,<br>
        Y. Morvan, <b>T. Hinks</b>, H. Carr, D.F. Laefer, C. O’Sullivan, W.S. Morrish,<br>
        <i>EuroGraphics 2008</i>, April 2008, Crete, Greece, pp. 215-218.        
      </p>
      <p>
        <a href="docs/eg2008-short-paper.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Impediments to vertical data capture from Aerial LiDAR for Three-dimensional Building Extraction”,<br>
        <b>T. Hinks</b>, H. Carr, D.F. Laefer,<br>
        <i>IABSE Symposium Report, IABSE Symposium, International Association for Bridge and Structural Engineering</i>, September 2007, Weimar, Germany, pp. 268-274.        
      </p>
    </li>
  </ul>

  <h2>Patents</h2>
  <ul>
    <li>
      <p>
        Robust Building Outline Extraction. PTO 56793223, Provisional filing May 2008, Full filing May 2009.
      </p>
    </li>
  </ul>

  <h2>Posters</h2>
  <ul>
    <li>
      <p>
        <a href="docs/year08_gold.png" target="_blank" rel="noopener">Gold medal</a> at Young European Arena of Research (YEAR), held in Ljubljana, Slovenia in April 2008. 
      </p>
      <p>
        <a href="docs/year08_poster.pdf" target="_blank" rel="noopener">poster [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Impediments to Vertical Data Capture from Aerial LiDAR for Three-dimensional Building Extraction”,<br>
        TRB 87th Annual Meeting, January 2008, Washington, DC, USA.        
      </p>
    </li>
  </ul>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>Projects</h2>

  <h3>Single-pass Wireframe Rendering</h3>
  <img src="images/wireframe_banner.png"
     style="max-width:100%; height:auto;">    
  <p>
    Wireframe rendering is normally done in two passes; the first renders the filled triangles and the second renders the lines, 
    using the depth buffer from the first pass to remove hidden lines. Not only does this involve passing the geometry twice to 
    the graphics card, there are issues with depth testing for the lines due to slight differences in rasterization techniques 
    between lines and triangles. These differences result in rendering artefacts and there is no good way to resolve this. In 
    2006 a new technique was proposed in a SIGGRAPH sketch entitled 
    <a href="docs/2006_single-pass_wireframe_rendering.pdf" target="_blank" rel="noopener">Single-pass Wireframe Rendering</a>. The technique uses a 
    pair of shaders to render triangles and lines in a single pass. Not only does this overcome rasterization issues, it is also faster 
    and produces smooth results. The main idea is to compute the distances from fragments to triangle edges. If a fragment is 
    within a threshold distance (half the line width) from a triangle edge, the fragment is rendered with the line color, 
    otherwise it is rendered with the triangle color. A smoothing function is applied at the boundary between triangle and line 
    to remedy aliasing artefacts. Most of the work is done in a vertex shader, where the distances to all triangle vertices are 
    computed in viewport space. It is these (interpolated) distances that are the input to the fragment shader. A more robust 
    implementation, using geometry shaders, has been proposed by <a href="docs/nvidia_solid_wireframe.pdf" target="_blank" rel="noopener">NVIDIA</a>. 
    Their implementation deals with some tricky cases 
    related to primitives having one or more vertices outside the viewing frustum and further reduces the amount of data sent 
    to the graphics card.  
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/wireframe_bunny1.png" target="_blank" rel="noopener">
          <img src="images/wireframe_bunny1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_bunny2.png" target="_blank" rel="noopener">
          <img src="images/wireframe_bunny2.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_buddha.png" target="_blank" rel="noopener">
          <img src="images/wireframe_buddha.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>

    <tr>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon3.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon3.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon1.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon2.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon2.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>

  <h3>GPU Smoke Rendering</h3>
  <img src="images/ghost_banner1.png"
     style="max-width:100%; height:auto;">    
  <p>
    Volumetric effects, such as smoke, are difficult to capture with standard rasterization techniques because light 
    interacts with volumes rather than surfaces. This real-time renderer was written for Naiad Studio and uses a volume 
    rendering approach based on camera-aligned proxy geometry and shaders. This method is well explained in 
    <a href="http://http.developer.nvidia.com/GPUGems/gpugems_ch39.html" target="_blank" rel="noopener">GPU Gems</a>. 
    Lighting equations are integrated by rendering proxy geometry in multiple passes, storing accumulated light in a 
    view buffer, while simultaneously accumulating visibility from a light source.  
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/ghost1.png" target="_blank" rel="noopener">
          <img src="images/ghost1.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/ghost2.png" target="_blank" rel="noopener">
          <img src="images/ghost2.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/ghost3.png" target="_blank" rel="noopener">
          <img src="images/ghost3.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
    </tr>
  </table>

  <h3>GPU Isosurface Rendering</h3>
  Iso-surfaces are ubiquitous in computer graphics, especially in applications where geometry undergoes significant topological changes over time. Level sets are a special type of iso-surface where the volumetric data is a Euclidean distance field. Fluid simulations often use level sets to track the fluid surfaces over time, using the distance zero-crossing to represent interfaces. This real-time renderer was written for Naiad Studio and uses a volume rendering approach based on camera-aligned proxy geometry and shaders. This method is well explained in GPU Gems. Volume data is stored as a 3D texture on the GPU and the fragments generated from the proxy geometry are used as sampling locations into this texture. This approach has several advantages over methods that extract explicit geometry from volumetric data (e.g. Marching Cubes). The distance field is shown “as is”, avoiding artefacts caused by super-imposed structures. Per-pixel shading is inherently provided and it becomes trivial to render any iso-value without additional setup.  

  <h3>Point Cloud Voxelization</h3>
  Large point cloud visualization is challenging because of the huge sizes of modern data sets. Additionally, using points as rendering primitives has significant drawbacks, that are further amplified in situations where large numbers of points are involved. Put simply, mathematical points have no volume, and, therefore do not cast shadows. Further, points have no surface area and no natural normal vector, which is commonly used for shading. Although, both volume and surface area can be approximated, it is difficult to get it right. An alternative is to use cubes as rendering primitives. Cubes have clearly defined volumes and six distinct surfaces, which means they can be rendered with traditional techniques.

  Cubes are created and stored in a hierarchical data structure known as an octree. Using a divide-and-conquer strategy, cubes are created to encapsulate the input point set. So, for each cube there is one or more data points inside its volume. The cubes are in fact the bounding boxes of the leaf nodes in the octree, which is recursively sub-divided to a user-defined depth. Data points are streamed, which means that there is no limit to the number of points being used in octree creation. Further, the memory footprint of the octree is orders of magnitude smaller than that of the raw points. The cubes are output to an OBJ-file, which can be rendered in real-time or offline. In the case of offline rendering (especially ray-tracing) it is possible to merge neighboring cube faces, to drastically reduce the amount of geometry to process (approx. an order of magnitude). This greatly speeds up rendering times without compromising visual quality. Images on the left were rendered with Maxwell.

  <h3>Preetham Sky Model</h3>
  The Preetham sky model simulates sky color for a given time (year, day of year and time of day) and location (latitude, longitude). The main idea is to compute the color at zenith and use a clever distribution technique to approximate the rest of the hemisphere. This leads to a cheap, closed-form solution that is reasonably close to meteorological measurements and relatively easy to implement. However, this model is not perfect, and a rigorous criticism was made recently. In spite of this, the Preetham sky model provides nice backgrounds to CG scenes, especially when compared to many of the simpler alternatives, such as single colors or gradients. The main alternative is to go out and acquire panoramic photographs of real skies, a task that requires expensive hardware and is time-consuming. Also, photographs cannot be animated over time, providing only static snapshots of lighting conditions. Finally, this implementation could be improved by adding physically based glare and some form of tone mapping.

  <h3>Level Set Ray Tracer</h3>
  This application ray traces level sets by using the signed distance function to determine safe distances for rays to “leap” into the data grid. Snow is applied by letting particles fall downward in a 4D simplex noise field and applying a union operation where particles collide with the level set. The build-up of snow is rather slow for small particles, but smaller particles yield a finer grained build-up where individual unions are not visible after a while.

  <h3>Moonlander 3D</h3>
  User input controls the moon lander’s five thrusters, visualized by simple particle systems. An inertial system determines rotation and translation of the lander. The moon lander was modeled in 3DS MAX. The main remaining problem here is how to divide thrustor forces between rotation and translation, or to be precise, how to determine the ratio between translation and rotation given a force at a certain point having with a known centre of mass. This factor has been estimated to “feel” good. The simulation was turned into a game, where the user tries to land at a given location within fuel constraints, which is more difficult than it might seem.

  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

</body>
</html>
