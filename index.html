<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tommy Hinks - Making numbers count</title>
</head>
<body style="font-family:sans-serif; max-width:800px; margin:3rem auto;">
  <h1>Tommy Hinks - Making numbers count</h1>
  <p>This page lists past and ongoing projects.</p>

  <h2>GitHub Repositories</h2>
  <p>
    For a complete list of GitHub repositories refer to my <a href="https://github.com/thinks" target="_blank" rel="noopener">GitHub profile</a>. 
  </p>
  <ul>
    <li>
      <a href="https://github.com/thinks/tph_poisson" target="_blank" rel="noopener">tph_poisson</a>
    </li>
    <li>
      <a href="https://github.com/thinks/fast-marching-method" target="_blank" rel="noopener">fast-marching-method</a>
    </li>
    <li>
      <a href="https://github.com/thinks/platonic-solids" target="_blank" rel="noopener">platonic-solids</a>
    </li>
    <li>
      <a href="https://github.com/thinks/obj-io" target="_blank" rel="noopener">obj-io</a>
    </li>
    <li>
      <a href="https://github.com/thinks/pnm-io" target="_blank" rel="noopener">pnm-io</a>
    </li>
  </ul>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>PhD<br>Geometric Processing Techniques for Urban Aerial Laser Scan Data</h2>
  <img src="images/phd_banner2.png"
     style="max-width:100%; height:auto;">  
  <p>
    My PhD studies focused on the acquisition and processing of high resolution Aerial Laser Scanning (ALS) data sets. In particular, processing task such as building extraction and modeling for urban areas were studied.
  </p>
  <h3>Abstract</h3>
  <p>
    Current Aerial Laser Scanning (ALS) technology rapidly produces large amounts of accurate point data for urban regions, making it a suitable tool for city-scale geometric modeling of buildings. However, acquisition and processing of urban ALS data remains a challenge because of the geometric complexity of urban scenes. Existing techniques have focused on geometric modeling from elevation data, ignoring details on building walls. This thesis introduces several improvements and simplifications for the acquisition and processing of ALS data: urban flight path planning, scan line analysis, visualization, building extraction, and simple and robust conversion of ALS data into solid models for further processing. By applying geometric reasoning, it is shown that certain flight paths vastly improve the point data quality on building walls. Single scan line analysis then exploits latent information in the data to insert missing echoes caused by undetected pulse reflections, and to identify building wall segments in individual scan lines. Points on building wall segments are then transferred to a digital image and complete building footprints are then extracted using innovative morphological techniques. Finally, a simple and robust method for direct conversion of point data into solid models based on volumetric subdivision rather than surface reconstruction is presented.
  </p>
  <p>
    <a href="docs/thinks-thesis-single.pdf" target="_blank" rel="noopener">thesis [.pdf]</a> | <a href="docs/viva_thinks.pdf" target="_blank" rel="noopener">presentation [.pdf]</a>
  </p>  

  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/phd_occlusion_full1.png" target="_blank" rel="noopener">
          <img src="images/phd_occlusion_full_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_maxwell_hfield2.png" target="_blank" rel="noopener">
          <img src="images/phd_maxwell_hfield_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_building_extraction1.pdf" target="_blank" rel="noopener">
          <img src="images/phd_building_extraction_thumb2.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/phd_fem_test3.png" target="_blank" rel="noopener">
          <img src="images/phd_fem_test_thumb1.webp" alt="" style="width:100px; height:auto;">
        </a>
      </td>
    </tr>
  </table>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>MSc<br>Animating Wind-Driven Snow Build-up Using an Implicit Approach</h2>
  <img src="images/snow_feldman3.png"
     style="max-width:600px; height:auto;">  
  <p>
    My master thesis focused on modeling snow buildup using implicit surfaces (more specifically level sets) by allowing snow to fall in a wind field. Level sets are propagated according to snow particle collisions, with constraints to mimic realistic buildup.
  </p>
  <p>
    <a href="docs/tommyfinalthesis.pdf" target="_blank" rel="noopener">thesis [.pdf]</a>
  </p>  
  <h3>Abstract</h3>
  <p>
    We present a physically-based snow modeling approach that handles geometrically complex scenes and arbitrary amounts of accumulated snow. Scene objects are represented with a novel dual level set structure. This implicit surface representation produces smooth snow surfaces that adhere to granular stability constraints at every timestep. Realistic accumulation patterns are achieved by tracing snow-carrying particles in a dynamic wind-field and on the surfaces of objects. Local level set operations are used to deposit snow at surface locations for which accumulation is physically plausible. The effectiveness of our method is demonstrated by applying our method to a number of challenging scenes.
  </p>
  <h3>Paper</h3>
  <p>
    “Wind-Driven Snow Buildup Using a Level Set Approach”,<br>
    <b>T. Hinks</b>, K. Museth,<br>
    <i>Eurographics Ireland Workshop Series</i>, Vol. 9, December 2009, Dublin, Ireland, pp. 19-26.  
  </p>
  <p>
    <a href="docs/eg09irl_snow.pdf" target="_blank" rel="noopener">paper [.pdf]</a> | <a href="docs/eg09irl_snow_pres.pdf" target="_blank" rel="noopener">presentation [.pdf]</a> - <span style="color: rgb(255, 136, 0);">Best presentation award!</span>
  </p>

  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420a.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420a.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420b.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420b.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_bunny_060420c.jpg" target="_blank" rel="noopener">
          <img src="images/snow_bunny_060420c.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>

    <tr>
      <td style="text-align:center;">
        <a href="images/snow_feldman.png" target="_blank" rel="noopener">
          <img src="images/snow_feldman.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_buddha.png" target="_blank" rel="noopener">
          <img src="images/snow_buddha.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/snow_lantern.jpg" target="_blank" rel="noopener">
          <img src="images/snow_lantern.jpg" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>Peer-reviewed Publications</h2>
  <ul>
    <li>
      <p>
        ”Visualisation of urban airborne laser scanning data with occlusion images”,<br>
        <b>T. Hinks</b>, H. Carr, H. Gharibi, D. Laefer,<br>
        <i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, Vol. 104, June 2015, pp. 77-87. <a href="https://dx.doi.org/10.1016/j.isprsjprs.2015.01.014" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        ”Point Cloud Data Conversion into Solid Models via Point-Based Voxelization”,<br>
        <b>T. Hinks</b>, H. Carr, L. Truong-Hong, D. Laefer,<br>
        <i>J. Surv. Eng.</i>, Vol. 139, No. 2, May 2013, pp. 72-83. <a href="https://dx.doi.org/10.1061/(ASCE)SU.1943-5428.0000097" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “Combining an Angle Criterion with Voxelization and the Flying Voxel Method in Reconstructing Building Models from LiDAR Data”,<br>
        L. Truong-Hong, D.F. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>Computer-Aided Civil and Infrastructure Engineering</i>, Vol. 28, No. 2, February 2013, pp. 112-129. <a href="https://dx.doi.org/10.1111/j.1467-8667.2012.00761.x" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “Flying Voxel Method with Delaunay Triangulation Criterion For Façade/Feature Detection For Computation”,<br>
        L. Truong-Hong, D. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>J. of Computing in Civil Eng.</i>, ASCE. <a href="https://dx.doi.org/10.1061/(ASCE)CP.1943-5487.0000188" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “New Advances in Automated Urban Modelling from Airborne Laser Scanning Data”,<br>
        D.F. Laefer, <b>T. Hinks</b>, H. Carr, L. Truong-Hong,<br>
        <i>Recent Patents on Engineering</i>, Bentham Science Publishers, Vol. 5, No. 3, December 2011, pp. 196-208. <a href="https://dx.doi.org/10.2174/187221211797636890" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
    <li>
      <p>
        “New possibilities for damage prediction from tunnel subsidence using aerial LiDAR data”,<br>
        D.F. Laefer, <b>T. Hinks</b>, H. Carr,<br>
        <i>Geotechnical Challenges in Megacities</i>, Vol. 2, June 7-10, 2010, ISSMGE Moscow, pp. 622-629.
      </p>
      <p>
        <a href="docs/2010_new_possibilities_for_damage_prediction_from_tunnel_subsidence_using_aerial_lidar_data.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Wind-Driven Snow Buildup Using a Level Set Approach”,<br>
        <b>T. Hinks</b>, K. Museth,<br>
        <i>Eurographics Ireland Workshop Series</i>, Vol. 9, December 2009, Dublin, Ireland, pp. 19-26.  
      </p>
      <p>
        <a href="docs/eg09irl_snow.pdf" target="_blank" rel="noopener">paper [.pdf]</a> | <a href="docs/eg09irl_snow_pres.pdf" target="_blank" rel="noopener">presentation [.pdf]</a> - <span style="color: rgb(255, 136, 0);">Best presentation award!</span>
      </p>
    </li>
    <li>
      <p>
        “Flight Optimization Algorithms for Aerial LiDAR Capture for Urban Infrastructure Model Generation”,<br>
        <b>T. Hinks</b>, H. Carr, D.F. Laefer,<br>
        <i>Journal of Computing in Civil Engineering</i>, Vol. 23, No. 4, November/December 2009, pp. 330-339.
      </p>
      <p>
        <a href="docs/jcce09.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Post Facto Registration Tools for Urban Modelling”,<br>
        Y. Morvan, <b>T. Hinks</b>, H. Carr, D.F. Laefer, C. O’Sullivan, W.S. Morrish,<br>
        <i>EuroGraphics 2008</i>, April 2008, Crete, Greece, pp. 215-218.        
      </p>
      <p>
        <a href="docs/eg2008-short-paper.pdf" target="_blank" rel="noopener">paper [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Impediments to vertical data capture from Aerial LiDAR for Three-dimensional Building Extraction”,<br>
        <b>T. Hinks</b>, H. Carr, D.F. Laefer,<br>
        <i>IABSE Symposium Report, IABSE Symposium, International Association for Bridge and Structural Engineering</i>, September 2007, Weimar, Germany, pp. 268-274. <a href="https://doi.org/10.2749/weimar.2007.0310" target="_blank" rel="noopener">DOI</a>
      </p>
    </li>
  </ul>

  <h2>Patents</h2>
  <ul>
    <li>
      <p>
        Robust Building Outline Extraction. PTO 56793223, Provisional filing May 2008, Full filing May 2009.
      </p>
    </li>
  </ul>

  <h2>Posters</h2>
  <ul>
    <li>
      <p>
        <a href="images/year08_gold.png" target="_blank" rel="noopener">Gold medal</a> at Young European Arena of Research (YEAR), held in Ljubljana, Slovenia in April 2008. 
      </p>
      <p>
        <a href="docs/year08_poster.pdf" target="_blank" rel="noopener">poster [.pdf]</a>
      </p>
    </li>
    <li>
      <p>
        “Impediments to Vertical Data Capture from Aerial LiDAR for Three-dimensional Building Extraction”,<br>
        TRB 87th Annual Meeting, January 2008, Washington, DC, USA.        
      </p>
    </li>
  </ul>
  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

  <h2>Projects</h2>

  <h3>Single-pass Wireframe Rendering</h3>
  <!-- <img src="images/wireframe_banner.png" style="max-width:100%; height:auto;"> -->
  <p>
    Wireframe rendering is traditionally performed in two passes: the first pass renders filled triangles, and the 
    second renders line primitives, using the depth buffer from the first pass to eliminate hidden lines. This 
    approach not only requires submitting geometry to the GPU twice, but also suffers from depth-testing issues 
    caused by subtle differences in rasterization between lines and triangles. These discrepancies often lead to 
    rendering artifacts for which there is no robust solution.
  </p>
  <p>
    In 2006, a new technique was introduced in a SIGGRAPH sketch titled 
    <a href="docs/2006_single-pass_wireframe_rendering.pdf" target="_blank" rel="noopener">Single-Pass Wireframe Rendering</a>. 
    This method employs a pair of shaders to render both triangles and wireframe edges in a single pass. In addition to 
    resolving rasterization inconsistencies, the technique is more efficient and produces smoother visual results. The core idea 
    is to compute the distance from each fragment to the edges of its corresponding triangle. If a fragment lies within 
    a specified threshold—typically half the desired line width—it is shaded with the line color; otherwise, it is shaded 
    with the triangle color. To mitigate aliasing, a smoothing function is applied at the transition between line and fill 
    regions.
  </p>
  <p>
    Most of the computation occurs in the vertex shader, where distances to all triangle edges are calculated in viewport 
    space. These values are then interpolated across the primitive and evaluated in the fragment shader. A more robust 
    variant of this approach, based on geometry shaders, has since been proposed by <a href="docs/nvidia_solid_wireframe.pdf" target="_blank" rel="noopener">NVIDIA</a>. 
    Their implementation addresses edge cases involving primitives with vertices outside the view frustum and further 
    reduces the amount of data sent to the GPU.    
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/wireframe_bunny1.png" target="_blank" rel="noopener">
          <img src="images/wireframe_bunny1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_bunny2.png" target="_blank" rel="noopener">
          <img src="images/wireframe_bunny2.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_buddha.png" target="_blank" rel="noopener">
          <img src="images/wireframe_buddha.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
    <tr>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon3.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon3.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon1.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/wireframe_dragon2.png" target="_blank" rel="noopener">
          <img src="images/wireframe_dragon2.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>

  <h3>GPU Smoke Rendering</h3>
  <p>
    Volumetric effects, such as smoke, are challenging to represent using standard rasterization techniques because 
    light interacts with participating media rather than with surfaces. This real-time renderer was developed for 
    Naiad Studio and employs a volume-rendering approach based on camera-aligned proxy geometry and GPU shaders. 
    The technique is described in detail in <i>GPU Gems</i> (<a href="https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-39-volume-rendering-techniques" target="_blank" rel="noopener">Chapter 39</a> 
    on volume rendering techniques).
  </p>
  <p>
    Lighting is evaluated by integrating the illumination equations through multiple rendering passes of the proxy geometry. During this process, accumulated light is stored in a view buffer while visibility from the light source is computed simultaneously. This approach enables efficient real-time rendering of complex volumetric lighting effects.    
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/ghost1.png" target="_blank" rel="noopener">
          <img src="images/ghost1.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/ghost2.png" target="_blank" rel="noopener">
          <img src="images/ghost2.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/ghost3.png" target="_blank" rel="noopener">
          <img src="images/ghost3.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
    </tr>
  </table>

  <h3>GPU Isosurface Rendering</h3>
  <p>
    Isosurfaces are ubiquitous in computer graphics, particularly in applications where geometry undergoes 
    significant topological changes over time. Level sets are a specific class of isosurfaces in which the 
    volumetric data represents a Euclidean distance field. In fluid simulations, level sets are commonly used 
    to track evolving fluid surfaces, with the zero-crossing of the distance field defining the interface.
  </p>
  <p>
    This real-time renderer was developed for Naiad Studio and employs a volume-rendering approach based on 
    camera-aligned proxy geometry and GPU shaders. The technique is described in detail in <i>GPU Gems</i> 
    (see <a href="https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-39-volume-rendering-techniques" target="_blank" rel="noopener">Chapter 39</a> 
    on volume rendering techniques). Volume data is stored as a 3D texture on the GPU, 
    and the fragments generated by the proxy geometry serve as sampling locations within this texture.
  </p>
  <p>
    Compared to methods that extract explicit geometry from volumetric data, such as Marching Cubes, this 
    approach offers several advantages. The distance field is rendered directly, avoiding artifacts introduced 
    by superimposed polygonal structures. Per-pixel shading is inherently supported, and arbitrary isovalues 
    can be rendered trivially without additional preprocessing or setup.
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/iso_fluid1.png" target="_blank" rel="noopener">
          <img src="images/iso_fluid1.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/iso_fluid2.png" target="_blank" rel="noopener">
          <img src="images/iso_fluid2.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/iso_fluid3.png" target="_blank" rel="noopener">
          <img src="images/iso_fluid3.png" alt="" style="width:auto; height:200px;">
        </a>
      </td>
    </tr>
  </table>

  <h3>Point Cloud Voxelization</h3>
  <!-- <img src="images/voxel_banner.png" style="max-width:100%; height:auto;"> -->
  <p>
    Visualizing large point clouds is challenging due to the sheer size of modern data sets. Moreover, using points as 
    rendering primitives introduces significant limitations, which become increasingly pronounced as the number of points 
    grows. In essence, mathematical points have no volume and therefore cannot cast shadows. They also lack surface area 
    and a well-defined normal vector, both of which are fundamental for conventional shading models. Although volume and 
    surface characteristics can be approximated, achieving accurate and visually convincing results is difficult. An 
    alternative approach is to use cubes as rendering primitives. Cubes possess well-defined volumes and six distinct 
    surfaces, allowing them to be rendered using traditional graphics techniques.
  </p>
  <p>
    Cubes are generated and stored in a hierarchical data structure known as an octree. Using a divide-and-conquer 
    strategy, cubes are constructed to encapsulate the input point set such that each cube contains one or more data 
    points within its volume. These cubes correspond to the bounding boxes of the octree's leaf nodes, which are 
    recursively subdivided to a user-defined depth. Data points are processed in a streaming manner, removing any 
    practical limit on the number of points that can be used to build the octree. As a result, the memory footprint 
    of the octree is several orders of magnitude smaller than that of the raw point data. The generated cubes are 
    exported to an OBJ file, enabling both real-time and offline rendering. For offline rendering, particularly in 
    ray tracing, adjacent cube faces can be merged to significantly reduce geometric complexity, often by 
    approximately an order of magnitude. This optimization substantially accelerates rendering times without 
    compromising visual quality. Images were rendered with <a href="https://maxwellrender.com" target="_blank" rel="noopener">Maxwell</a>.
  </p>
  <h4>Digital Dublin / VoxelVille</h4>
  <p>
    The image below was shortlisted for the UCD Image of Research Competition 2008. The input point set for this image 
    was part of a high-grade aerial laser scan of the city of Dublin.
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/voxel_digital_dublin.png" target="_blank" rel="noopener">
          <img src="images/voxel_digital_dublin.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>
  <h4>Radiohead - House of Cards</h4>
  <p>
    Famous rockband <a href="https://www.radiohead.com" target="_blank" rel="noopener">Radiohead</a> generously 
    released the data captured during the making of the video for their single 
    <a href="https://open.spotify.com/track/48X4D1FYOShPz2VF3YdfCF?si=6ac06c8fc86c4059" target="_blank" rel="noopener">House of Cards</a>. The data consists of 
    several thousand frames of real-time laser scan data of singer Thom Yorke's face. A few frames are shown below. 
    Two levels of voxelization, rendered in different colors, are overlaid and rendered with depth-of-field and 
    motion blur. Finally, the images were post-processed to remove some saturation from the green and blue channels.
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/voxel_hoc1.png" target="_blank" rel="noopener">
          <img src="images/voxel_hoc1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/voxel_hoc6.png" target="_blank" rel="noopener">
          <img src="images/voxel_hoc6.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/voxel_hoc41.png" target="_blank" rel="noopener">
          <img src="images/voxel_hoc41.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>

  <h3>Preetham Sky Model</h3>
  <!-- <img src="images/sky_banner1.png" style="max-width:100%; height:auto;"> -->
  <p>
    The <a href="docs/1999_a_practical_analytic_model_for_daylight.pdf" target="_blank" rel="noopener">Preetham sky model</a> 
    simulates sky color for a given time and geographic location, specified by latitude and longitude. The core idea is 
    to compute the sky color at the zenith and then use a carefully designed distribution function to approximate radiance 
    across the rest of the hemisphere. This results in a computationally inexpensive, closed-form solution that reasonably 
    matches meteorological measurements and is relatively straightforward to implement.
  </p>
  <p>
    Despite its advantages, the model is not without shortcomings, and a 
    <a href="docs/2007_a_critical_review_of_the_preetham_skylight_model.pdf" target="_blank" rel="noopener">rigorous critique</a> has been published in 
    recent years. Nevertheless, the Preetham sky model remains well suited for generating visually pleasing sky 
    backgrounds in computer graphics, particularly when compared to simpler alternatives such as constant colors 
    or linear gradients. A primary alternative is capturing panoramic photographs of real skies, but this approach 
    requires costly equipment, is time-consuming, and produces only static lighting snapshots that cannot be 
    animated over time.
  </p>
  <p>
    This implementation could be further improved by incorporating physically based glare effects and an 
    appropriate tone-mapping operator.
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/sky_key.png" target="_blank" rel="noopener">
          <img src="images/sky_key.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/sky1.png" target="_blank" rel="noopener">
          <img src="images/sky1.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/sky2.png" target="_blank" rel="noopener">
          <img src="images/sky2.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
    <tr>
      <td style="text-align:center;">
        <a href="images/sky3.png" target="_blank" rel="noopener">
          <img src="images/sky3.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/sky4.png" target="_blank" rel="noopener">
          <img src="images/sky4.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
      <td style="text-align:center;">
        <a href="images/sky5.png" target="_blank" rel="noopener">
          <img src="images/sky5.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>


  <h3>Level Set Ray Tracer</h3>
  <p>
    This application ray traces level sets using a signed distance function (SDF) to compute safe step 
    sizes that allow rays to efficiently “leap” through the grid. Snow accumulation is simulated by 
    allowing particles to fall downward through a 4D simplex noise field and applying a union operation 
    when particles collide with the level set. While snow buildup progresses slowly for small particles, 
    reducing particle size produces a finer-grained accumulation in which individual union operations 
    become imperceptible over time.
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/lsrt_bunny.png" target="_blank" rel="noopener">
          <img src="images/lsrt_bunny.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>

  <h3>Moon Lander 3D</h3>
  <p>
    User input controls the moon lander’s five thrusters, which are visualized using simple particle systems. 
    An inertial model governs the lander’s rotation and translation. The primary remaining challenge was 
    determining how to correctly distribute thruster forces between rotational and translational motion. 
    For this project, a simple, pragmatic solution was chosen, optimized to “feel” right rather than to be 
    physically exact.
  </p>
  <p>
    The simulation was ultimately developed into a game in which the player must land at a designated location 
    while managing limited fuel; a task that proves more challenging than it might initially appear.    
  </p>
  <table style="margin:auto; border-collapse: separate; border-spacing: 20px;">
    <tr>
      <td style="text-align:center;">
        <a href="images/moon_lander.png" target="_blank" rel="noopener">
          <img src="images/moon_lander.png" alt="" style="width:200px; height:auto;">
        </a>
      </td>
    </tr>
  </table>

  <hr style="border:none; border-top:1px solid #ccc; margin:2rem 0;">

</body>
</html>
